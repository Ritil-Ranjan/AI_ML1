{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0a0ace4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b66c0020",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def calc_iou(a, b): # a is n*4 matrix whereas b is m*4 matrix where i_th row is [x_min, y_min, x_max, y_max] for both\n",
    "    # a denotes predicted bounding box whereas b denotes ground truth bounding box, or vice versa.\n",
    "    area_b = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1]) # area is array of size m.\n",
    "\n",
    "    iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\n",
    "    ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\n",
    "    # iw and ih are n*m matrices whose (i, j)_th element denote respectively the width and height of the intersecting\n",
    "    # rectangle between i_th bounding box of a and j_th bounding of b. \n",
    "    # 2 disconnected bounding boxes will have negative width or height of intersecting rectangle.\n",
    "    iw = torch.clamp(iw, min=0) # this increases any negative element of iw to 0.\n",
    "    ih = torch.clamp(ih, min=0) # this increases any negative element of ih to 0.\n",
    "\n",
    "    intersection = iw * ih # intersection is n*m matrix giving intersecting area\n",
    "    \n",
    "    ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area_b - intersection\n",
    "    # ua is n*m matrix whose (i, j)_th element gives the area of union of i_th bounding box of a\n",
    "    # and j_th bounding box of b.\n",
    "    ua = torch.clamp(ua, min=1e-8) # we want a very small positive value to avoid division by 0.\n",
    "\n",
    "    IoU = intersection / ua # IoU is n*m matrix\n",
    "\n",
    "    return IoU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d436f-20ae-45df-a214-999e154bd3c4",
   "metadata": {},
   "source": [
    "# p = batch_size\n",
    "# q = no. of predicted bounding box\n",
    "# r = no. of classes\n",
    "# t = no. of ground truth bounding box\n",
    "# s = no. of ground truth bounding boxes recognising foreground in a particular image\n",
    "# u = no. of predicted bounding boxes in a particular image whose IoU with atleast one ground truth bounding box is greater than or equal to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "577f65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    #def __init__(self):\n",
    "\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        # classifications is a p*q*r array where p is batch_size, i.e. total number of images in each batch of SGD, q is total number\n",
    "        # of predicted bounding box for each image (assume same number of predicted bounding box for each image)\n",
    "        # which is also same as number of anchor boxes and r is total number of classes. Thus its (i, j, k)_th\n",
    "        # element depicts the probability that the j_th predicted bounding box of i_th image belongs to k_th class.\n",
    "\n",
    "        # regressions is a p*q*4 array whose (i, j)_th element is [x_min, y_min, x_max, y_max] for j_th predicted\n",
    "        # bounding box for i_th image\n",
    "\n",
    "        # anchors is a p*q*4 array whose (i, j)_th element is [x_min, y_min, x_max, y_max] for j_th anchor box in\n",
    "        # i_th image. Anchor boxes are predefined before the training starts.\n",
    "\n",
    "        # annotations is p*t*5 array where t is the number of annotations, which is maximum number of objects in\n",
    "        # any image which is same as the number of ground truth bounding box in each image. Its (i, j)_th element\n",
    "        # is [x_min, y_min, x_max, y_max, class_id] for j_th ground truth\n",
    "        # bounding box in i_th image. class_id will be -1 for background, i.e. no actual object. \n",
    "\n",
    "        alpha = 0.25 # balancing factor for positive and negative samples\n",
    "        gamma = 2.0 # focussing parameter\n",
    "        batch_size = classifications.shape[0] # =p\n",
    "        classification_losses = [] # array initialisation\n",
    "        regression_losses = [] # They will store the losses for each image\n",
    "\n",
    "        anchor = anchors[0, :, :] # We assume same anchor boxes for all the images, so it is matrix of size t*5\n",
    "\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0] # array of size q denoting width\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1] # array of size q denoting height\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths # array of size q denoting abscissa of centre\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights # array of size q denoting ordinate of centre\n",
    "\n",
    "        for j in range(batch_size): # for j = 1 to p\n",
    "            classification = classifications[j, :, :] # matrix of size q*r\n",
    "            regression = regressions[j, :, :] # matrix of size q*4\n",
    "\n",
    "            bbox_annotation = annotations[j, :, :] # matrix of size t*5\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1] # remove those ground truth bounding boxes\n",
    "            # which recognise no object. Let the new size be s*5, so s<=t\n",
    "\n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4) # assume that all the probabilities lie\n",
    "            # between 0.0001 and 0.9999 so that when we take log(x) or log(1-x) then numerical stability is maintained\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0: # if there is no ground truth bounding box\n",
    "                if torch.cuda.is_available(): # if GPU is available\n",
    "                    alpha_factor = torch.ones(classification.shape).cuda() * alpha # alpha_factor is a tensor of\n",
    "                    # same shape as classfication and all its elements are alpha, i.e. 0.25. Element wise\n",
    "                    # multiplication is performed by GPU.\n",
    "\n",
    "                    alpha_factor = 1. - alpha_factor # It is a q*r matrix filled with 0.75\n",
    "                    focal_weight = classification # q*r matrix\n",
    "                    focal_weight = alpha_factor * torch.pow(focal_weight, gamma) # (1-α) * (p^γ)\n",
    "\n",
    "                    bce = -(torch.log(1.0 - classification)) # Binary CrossEntropy Loss = -log(1-p)\n",
    "\n",
    "                    # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "                    cls_loss = focal_weight * bce # -(1-α) * (p^γ) * log(1-p)\n",
    "                    classification_losses.append(cls_loss.sum()) # sum of all q*r elements\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda()) # Since there is no ground truth\n",
    "                    # bounding box so regression loss is 0\n",
    "\n",
    "                else: # if GPU is not available, all calculations are exactly same\n",
    "                    alpha_factor = torch.ones(classification.shape) * alpha\n",
    "\n",
    "                    alpha_factor = 1. - alpha_factor\n",
    "                    focal_weight = classification\n",
    "                    focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "\n",
    "                    bce = -(torch.log(1.0 - classification))\n",
    "\n",
    "                    # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "                    cls_loss = focal_weight * bce\n",
    "                    classification_losses.append(cls_loss.sum())\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "\n",
    "                continue # go to next image, i.e. next iteration in for loop, i.e. j++\n",
    "            # else there is atleast 1 ground truth box\n",
    "            \n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\n",
    "            # IoU is q*s matrix for finding IoU between i_th predicted and j_th ground truth bounding box.\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1) # IoU_max and IoU_argmax are arrays of size q whose\n",
    "            # i_th element denote maximum IoU and the index of ground truth bounding box having maximum IoU\n",
    "            # respectively with the i_th predicted bounding box.\n",
    "\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "\n",
    "            # compute the loss for classification\n",
    "            targets = torch.ones(classification.shape) * -1 # targets is q*r matrix filled with -1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                targets = targets.cuda() # Why dont we do similar kind of thing in no ground truth bounding box?\n",
    "\n",
    "            targets[torch.lt(IoU_max, 0.4), :] = 0 # if i_th element of IoU_max is less than 0.4 then all elements\n",
    "            # of i_th row of targets is changed to 0\n",
    "\n",
    "            positive_indices = torch.ge(IoU_max, 0.5) # positive_indices is an array of size q whose i_th element\n",
    "            # will be 1 if i_th element of IoU_max >= 0.5 else 0.\n",
    "\n",
    "            num_positive_anchors = positive_indices.sum() # it finds the number of indices of IoU_max having\n",
    "            # value greater than or equal to 0.5\n",
    "\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :] # assigned_annotations is a q*5 matrix whose i_th\n",
    "            # row is the IoU_argmax[i]_th row of bbox_notation. Since IoU_argmax contains the index of the groun truth\n",
    "            # bounding box most closely associated with the given index so it is guaranteed to be greater than or\n",
    "            # equal to 0 but less than t. Note that it is possible that a particular ground truth bounding box is most\n",
    "            # closely associated with multiple or no predicted bounding box. Thus some of the rows in\n",
    "            # assigned_annotations may be repeated or some rows of bbox_annotation may not be present in\n",
    "            # assigned_annotations. Thus i_th row of assigned_annotations returns [x_min, y_min, x_max, y_max, \n",
    "            # class_id] of the ground truth bounding box which is most closely associated to the i_th predicted\n",
    "            # bounding box.\n",
    "\n",
    "            targets[positive_indices, :] = 0 # if i_th element of positive_indices is 1 then all elements of i_th row\n",
    "            # of targets will become 0.\n",
    "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1 # if i_th element of\n",
    "            # positive_indices is 1 and (i, 4)_th element of assigned_annotations is j then (i, j)_th element of\n",
    "            # targets will become 1. .long() is used to convert class labels into integers.\n",
    "            \n",
    "            # Thus, (i, j)_th element of targets will be:-\n",
    "            #     1 iff i_th predicted bounding box belongs to j_th class. This will happen iff i_th element of \n",
    "            #         IoU_max is greater than or equal to 0.5 and i_th element of IoU_argmax is j.\n",
    "            #     -1 iff i_th predicted bounding box has IoU_max less than 0.5 but greater than or equal to 0.4. \n",
    "            #         This denotes that it is difficult to make predictions about class.\n",
    "            #     0 Otherwise. This denotes that most probably i_th predicted bounding box does not belong to j_th\n",
    "            #         class.\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                alpha_factor = torch.ones(targets.shape).cuda() * alpha\n",
    "            else: # alpha_factor is a q*r matrix filled with 0.25\n",
    "                alpha_factor = torch.ones(targets.shape) * alpha\n",
    "\n",
    "            alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)\n",
    "            # if (i, j)_th element of targets is not 1 then (i, j)_th element of alpha_factor will be subtracted from 1.\n",
    "            focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)\n",
    "            # focal_weight is q*r matrix whose (i, j)_th element will be (i, j)_th element of classification iff\n",
    "            # (i, j)_th element of targets is not 1, else it will be 1 - (i, j)_th element of classification\n",
    "            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\n",
    "\n",
    "            bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))\n",
    "            # bce is q*r matrix\n",
    "\n",
    "            # cls_loss = focal_weight * torch.pow(bce, gamma)\n",
    "            cls_loss = focal_weight * bce # cls_loss is q*r matrix\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape).cuda())\n",
    "            else: # if (i, j)_th element of targets was -1, then (i, j)_th element of cls_loss will be 0\n",
    "            # This step is done because it was difficult to make class prediction for this bounding box\n",
    "                cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, torch.zeros(cls_loss.shape))\n",
    "\n",
    "            classification_losses.append(cls_loss.sum()/torch.clamp(num_positive_anchors.float(), min=1.0))\n",
    "            # We append average of classification loss for this image. In case IoU_max < 0.5 for all elements we dont\n",
    "            # want division by 0\n",
    "\n",
    "            # compute the loss for regression\n",
    "\n",
    "            if positive_indices.sum() > 0: # If atleast one element of IoU_max is greater than or equal to 0.5\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :] # Remove those predicted bounding\n",
    "                # boxes whose corresponding IoU_max is less than 0.5. Let the new size be u*5. So u <= q.\n",
    "                \n",
    "                # Similarly do the above thing for predicted bounding boxes' dimensions and centre coordinates.\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices] # These are arrays of size u.\n",
    "\n",
    "                # Similarly we do above thing for ground truth bounding boxes\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights # These are arrays of size u.\n",
    "\n",
    "                # clip widths to 1\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1) \n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                # Loss terms:-\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh)) # target becomes a matrix of\n",
    "                # size 4 * u\n",
    "                targets = targets.t() # it becomes a matrix of size u * 4\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else: # all elements of the 0_th and 1_st coloum of targets is divided by 0.1 whereas those of 2nd and\n",
    "                # 3rd coloum are divided by 0.2.\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                negative_indices = 1 + (~positive_indices) # It is an array of size q whose i_th element os 1 if i_th\n",
    "                # element of positive_indices is 1 else it is 2. ~ is used to perform element wise bitwise NOT\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :]) # regression_diff is a matrix\n",
    "                # size u*4 whose i_th row gives the absolute difference between predicted and error values of \n",
    "                # dimensions and centre coordinates of bounding box\n",
    "\n",
    "                regression_loss = torch.where( # regression loss is u*4 matrix whose (i, j)_th element will be\n",
    "                    torch.le(regression_diff, 1.0 / 9.0), # 4.5 * regression_diff[i, j]^2 iff regression_diff[i, j]\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2), # is less than 1/9, else it will be \n",
    "                    regression_diff - 0.5 / 9.0 # regression_diff[i, j] - 1/18. This is HUBER LOSS.\n",
    "                )\n",
    "                regression_losses.append(regression_loss.mean()) \n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "        # All elements of classification_losses and regression_losses are scalars.\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)\n",
    "        # torch.stack() is used to convert the list to pytorch tensor. dim = 0 and keepdim = True was explcitly written\n",
    "        # a list of 2 tensors is returned, and not a list of 2 scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99df0e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        batch_size = classifications.shape[0]\n",
    "        classification_losses = []\n",
    "        regression_losses = []\n",
    "\n",
    "        anchor = anchors[0, :, :]\n",
    "\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0]\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            classification = classifications[j, :, :]\n",
    "            regression = regressions[j, :, :]\n",
    "\n",
    "            bbox_annotation = annotations[j, :, :]\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(1).float().cuda())\n",
    "                    classification_losses.append(torch.tensor(1).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(1).float())\n",
    "                    classification_losses.append(torch.tensor(1).float())\n",
    "                continue\n",
    "\n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)\n",
    "\n",
    "            # compute the loss for classification\n",
    "            targets = torch.ones(classification.shape) * -1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            targets[torch.lt(IoU_max, 0.4), :] = 0\n",
    "\n",
    "            positive_indices = torch.ge(IoU_max, 0.5)\n",
    "\n",
    "            num_positive_anchors = positive_indices.sum()\n",
    "\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :]\n",
    "\n",
    "            targets[positive_indices, :] = 0\n",
    "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1\n",
    "\n",
    "            t = annotations.shape[1]\n",
    "            s = bbox_annotation.shape[0]\n",
    "            q = classification.shape[0]\n",
    "            r = classification.shape[1]\n",
    "            \n",
    "            true_labels = torch.zeros(q, r)\n",
    "            if torch.cuda.is_available():\n",
    "                true_labels = true_labels.cuda()\n",
    "            for k in range(q):\n",
    "                l = IoU_argmax[k]\n",
    "                m = bbox_annotation[l, 4].long()\n",
    "                true_labels[k, m] = 1\n",
    "\n",
    "            numerator = torch.zeros(q)\n",
    "            denominator = torch.zeros(q)\n",
    "            for k in range(q):\n",
    "                numerator[k] = torch.dot(classification[k], true_labels[k])\n",
    "                denominator[k] = torch.sum(classification[k]) + torch.sum(true_labels[k])\n",
    "\n",
    "            dice_loss = 1 - 2 * numerator / denominator\n",
    "            classification_losses.append(dice_loss.mean())\n",
    "            \n",
    "\n",
    "            \n",
    "            # compute the loss for regression\n",
    "\n",
    "            if positive_indices.sum() > 0: # If atleast one element of IoU_max is greater than or equal to 0.5\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :] # Remove those predicted bounding\n",
    "                # boxes whose corresponding IoU_max is less than 0.5. Let the new size be u*5. So u <= q.\n",
    "                \n",
    "                # Similarly do the above thing for predicted bounding boxes' dimensions and centre coordinates.\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices] # These are arrays of size u.\n",
    "\n",
    "                # Similarly we do above thing for ground truth bounding boxes\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights # These are arrays of size u.\n",
    "\n",
    "                # clip widths to 1\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1) \n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                # Loss terms:-\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh)) # target becomes a matrix of\n",
    "                # size 4 * u\n",
    "                targets = targets.t() # it becomes a matrix of size u * 4\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else: # all elements of the 0_th and 1_st coloum of targets is divided by 0.1 whereas those of 2nd and\n",
    "                # 3rd coloum are divided by 0.2.\n",
    "                    targets = targets/torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                negative_indices = 1 + (~positive_indices) # It is an array of size q whose i_th element os 1 if i_th\n",
    "                # element of positive_indices is 1 else it is 2. ~ is used to perform element wise bitwise NOT\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :]) # regression_diff is a matrix\n",
    "                # size u*4 whose i_th row gives the absolute difference between predicted and error values of \n",
    "                # dimensions and centre coordinates of bounding box\n",
    "\n",
    "                regression_loss = torch.where( # regression loss is u*4 matrix whose (i, j)_th element will be\n",
    "                    torch.le(regression_diff, 1.0 / 9.0), # 4.5 * regression_diff[i, j]^2 iff regression_diff[i, j]\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2), # is less than 1/9, else it will be \n",
    "                    regression_diff - 0.5 / 9.0 # regression_diff[i, j] - 1/18. This is HUBER LOSS.\n",
    "                )\n",
    "            \n",
    "                regression_losses.append(regression_loss.mean())\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c32085f-2138-4e3e-af5b-9a65e247c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss2(nn.Module):\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        batch_size = classifications.shape[0]\n",
    "        classification_losses = []\n",
    "        regression_losses = []\n",
    "\n",
    "        anchor = anchors[0, :, :]\n",
    "\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0]\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            classification = classifications[j, :, :]\n",
    "            regression = regressions[j, :, :]\n",
    "\n",
    "            bbox_annotation = annotations[j, :, :]\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(1).float().cuda())\n",
    "                    classification_losses.append(torch.tensor(1).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(1).float())\n",
    "                    classification_losses.append(torch.tensor(1).float())\n",
    "                continue\n",
    "\n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)\n",
    "            positive_indices = torch.ge(IoU_max, 0.5)\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :]\n",
    "            \n",
    "            # Compute true labels\n",
    "            true_labels = torch.zeros_like(classification)\n",
    "            if torch.cuda.is_available():\n",
    "                true_labels = true_labels.cuda()\n",
    "            true_labels[torch.arange(true_labels.shape[0]), bbox_annotation[IoU_argmax, 4].long()] = 1\n",
    "\n",
    "            # Compute Dice loss\n",
    "            numerator = torch.sum(classification * true_labels, dim=1)\n",
    "            denominator = torch.sum(classification, dim=1) + torch.sum(true_labels, dim=1)\n",
    "            dice_loss = 1 - 2 * numerator / denominator\n",
    "\n",
    "            classification_losses.append(dice_loss.mean())\n",
    "\n",
    "            # Compute regression loss (same as FocalLoss)\n",
    "            if positive_indices.sum() > 0:\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :]\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
    "\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights\n",
    "\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1)\n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh)).t()\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets / torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else:\n",
    "                    targets = targets / torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :])\n",
    "                regression_loss = torch.where(\n",
    "                    torch.le(regression_diff, 1.0 / 9.0),\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\n",
    "                    regression_diff - 0.5 / 9.0\n",
    "                )\n",
    "                regression_losses.append(regression_loss.mean())\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4762624-71b3-4049-803d-6e9120f87aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIoULoss(nn.Module):\n",
    "    def forward(self, classifications, regressions, anchors, annotations):\n",
    "        batch_size = classifications.shape[0]\n",
    "        classification_losses = []\n",
    "        regression_losses = []\n",
    "\n",
    "        anchor = anchors[0, :, :]\n",
    "\n",
    "        anchor_widths  = anchor[:, 2] - anchor[:, 0]\n",
    "        anchor_heights = anchor[:, 3] - anchor[:, 1]\n",
    "        anchor_ctr_x   = anchor[:, 0] + 0.5 * anchor_widths\n",
    "        anchor_ctr_y   = anchor[:, 1] + 0.5 * anchor_heights\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            classification = classifications[j, :, :]\n",
    "            regression = regressions[j, :, :]\n",
    "\n",
    "            bbox_annotation = annotations[j, :, :]\n",
    "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\n",
    "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\n",
    "\n",
    "            if bbox_annotation.shape[0] == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(1).float().cuda())\n",
    "                    classification_losses.append(torch.tensor(1).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(1).float())\n",
    "                    classification_losses.append(torch.tensor(1).float())\n",
    "                continue\n",
    "\n",
    "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\n",
    "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)\n",
    "            positive_indices = torch.ge(IoU_max, 0.5)\n",
    "            assigned_annotations = bbox_annotation[IoU_argmax, :]\n",
    "            \n",
    "            # Compute true labels\n",
    "            true_labels = torch.zeros_like(classification)\n",
    "            if torch.cuda.is_available():\n",
    "                true_labels = true_labels.cuda()\n",
    "            true_labels[torch.arange(true_labels.shape[0]), bbox_annotation[IoU_argmax, 4].long()] = 1\n",
    "\n",
    "            # Compute Dice loss\n",
    "            numerator = torch.sum(classification * true_labels, dim=1)\n",
    "            denominator = torch.sum(classification, dim=1) + torch.sum(true_labels, dim=1)\n",
    "            N = 2\n",
    "            dice_loss = 1 - (N+1) * numerator / (denominator * N*numerator)\n",
    "\n",
    "            classification_losses.append(dice_loss.mean())\n",
    "\n",
    "            # Compute regression loss (same as FocalLoss)\n",
    "            if positive_indices.sum() > 0:\n",
    "                assigned_annotations = assigned_annotations[positive_indices, :]\n",
    "                anchor_widths_pi = anchor_widths[positive_indices]\n",
    "                anchor_heights_pi = anchor_heights[positive_indices]\n",
    "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\n",
    "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\n",
    "\n",
    "                gt_widths  = assigned_annotations[:, 2] - assigned_annotations[:, 0]\n",
    "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\n",
    "                gt_ctr_x   = assigned_annotations[:, 0] + 0.5 * gt_widths\n",
    "                gt_ctr_y   = assigned_annotations[:, 1] + 0.5 * gt_heights\n",
    "\n",
    "                gt_widths  = torch.clamp(gt_widths, min=1)\n",
    "                gt_heights = torch.clamp(gt_heights, min=1)\n",
    "\n",
    "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\n",
    "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\n",
    "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\n",
    "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\n",
    "\n",
    "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh)).t()\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    targets = targets / torch.Tensor([[0.1, 0.1, 0.2, 0.2]]).cuda()\n",
    "                else:\n",
    "                    targets = targets / torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\n",
    "\n",
    "                regression_diff = torch.abs(targets - regression[positive_indices, :])\n",
    "                regression_loss = torch.where(\n",
    "                    torch.le(regression_diff, 1.0 / 9.0),\n",
    "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\n",
    "                    regression_diff - 0.5 / 9.0\n",
    "                )\n",
    "                regression_losses.append(regression_loss.mean())\n",
    "            else:\n",
    "                if torch.cuda.is_available():\n",
    "                    regression_losses.append(torch.tensor(0).float().cuda())\n",
    "                else:\n",
    "                    regression_losses.append(torch.tensor(0).float())\n",
    "\n",
    "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0, keepdim=True)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
